hist(training$capitalAve, main='')
hist(training$capitalAve, main='', xlab='average length of capital run')
mean(training$capitalAve)
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve-mean(trainCapAve)/sd(trainCapAve)
?
)
trainCapAveS <- (trainCapAve-mean(trainCapAve))/sd(trainCapAve)
qplot(trainCapAveS)
qplot(trainCapAveS, geom='density')
qplot(trainCapAveS, geom='density', log='x')
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve))/sd(trainCapAve)
table(testCapAveS)
summary(testCapAveS)
summary(trainCapAveS)
sd(trainCapAve)
sd(trainCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58], method=c('center', 'scale'))
preObj <- preProcess(training[,-58], method=c('center', 'scale'))
preObj
trainCapAveS <- predict(preObj, trainig[,-58])$capitalAve
trainCapAveS <- predict(preObj, training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- predict(preObj, testing[, -58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(323343)
modelFit <- train(type~., data=training, preProcess=c('center', 'scale'), method='glm')
modelFit
preObj <- preProcess(training[,-58], method = c('BoxCox'))
trainingAveS <- predict(preObj, training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
trainCapAveS <- predict(preObj, training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
set.seed(13343)
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1], size=1, prob=0.05) == 1
selectNA
sum(selectNA)
mean(selectNA)
training$capAve[selectNA] <- NA
preObj <- preProcess(training[, -58], method='knnImpute')
capAve <- predict(preObj, training[,-58])$capAve
capAve
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve, capAveTruth)
quantile(capAve-capAveTruth)
inTrain <- createDataPartition(Wage$wage, p=0.7, list=F)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummVars(wage ~ jobclass, data=training)
dummies <- dummyVars(wage ~ jobclass, data=training)
dummies
predict(dummies, newdata=training)
head(predict(dummies, newdata=training),10)
nsv <- nearZeroVar(training, saveMetrics=T)
nsv
testing$sex
nsv
library(splines)
bsBasic <- bs(training$age, df=3)
bsBasic
lm1 <- lm(wage ~ bsBasic, data=training)
plot(training$age, training$wage, pch=19, cex=0.5)
?plot
points(training$age, predict(lm1, newdata=training), col='red', pch=19, cex=0.5)
predict(bsBasic, age=testing$age)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(spam$type, p=0.75, list = F)
inTrain
training <- spam[inTrain,]
testing <- spam[-inTrain,]
testing
dim(testing)
dim(training)
dim(spam)
M <- abs(cor(training[, -58]))
M
dim(M)
M
?which
diag(M)
diag(M) <- 0
M
which(M>0.8)
which(M>0.8, arr.ind=T)
which(M>0.8, arr.ind=F)
which(M>0.8, arr.ind=T)
which(M>0.8, arr.ind=T)
M <- abs(cor(training[, -58]))
diag(M) <- 0
which(M>0.8, arr.ind=F)
which(M>0.8, arr.ind=T)
names(spam)[c(34,32)]
qplot(spam[,34], spam[,32])
plot(spam[,34], spam[,32])
plot(spam[,34], spam[,32])
qplot(spam[,34], spam[,32])
qplot(spam[,34], spam[,32])
qplot(spam[,40], spam[,32])
cor(spam[,40], spam[,32])
spam[,40]
qplot(spam[,40], spam[,32])
qplot(spam[,34], spam[,32])
smallSpam <- spam[, c(34,32)]
smallSpam
rownames(smallSpam)
colnames(smallSpam)
prComp <- prcomp(smallSpam)
prComp
prComp$x
prComp$y
qplot(prComp$x[,1], prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1+1)
typeColor
prComp <- prcomp(log10(spam[,-58]+1))
qplot(prComp$x[,1], prComp$x[,2], col=typeColor)
preProc <- preProcess(log10(spam[,-58]+1), method="pca", pcaComp=2)
spamPC <- predict(preProc, newdata=log10(spam,-58)+1)
spamPC <- predict(preProc, newdata=log10(spam[,-58])+1)
spamPC
spamPC <- predict(preProc, log10(spam[,-58])+1)
spamPC
qplot(spamPC[,1], spamPC[,2])
preProc <- preProcess(log10(spam[,-58])+1, method="pca", pcaComp=2)
preProc <- preProcess(log10(spam[,-58])+1, method="pca", pcaComp=2)
preProc <- preProcess(log10(spam[,-58]+1), method="pca", pcaComp=2)
preProc
spamPC <- predict(preProc, log10(spam[,-58]+1))
spamPC
qplot(spamPC[,1], spamPC[,2])
qplot(spamPC[,1], spamPC[,2], col=typeColor)
preProc <- preProcess(log10(training[,-58]+1), method='pca', pcaComp = 2)
trainPC <- predict(preProc, log10(training[,-58]+1))
trainPC
modelFit <- train(training$type ~ ., method='glm', data=trainPC )
modelFit
warnings()
modelFit
testPC <- predict(preProc, log10(testing[,-58]+1))
testPC
confusionMatrix(testing$type, predict(modelFit,testPC))
modelFit <- train(training$type ~., method='glm', preProcess='pca', data=training)
confusionMatrix(testing$type, predict(modelFit, testing))
library(caret)
data(faithful)
dim(faithful)
faithful
colnames(faithful)
inTrain <- createDataPartition(faithful$waiting, p=0.5, list=F)
training <- faithful[inTrain,]
testing <- faithful[-inTrain,]
head(training)
?plot
qplot(training$waiting, training$eruptions)
qplot(training$waiting, training$eruptions, pch=18)
qplot(training$waiting, training$eruptions, pch=19)
plot(training$waiting, training$eruptions, pch=19)
plot(training$waiting, training$eruptions, pch=19)
plot(training$waiting, training$eruptions, pch=19)
plot(training$waiting, training$eruptions, pch=19, col='blue')
qplot(training$waiting, training$eruptions, pch=19, col='blue')
qplot(training$waiting, training$eruptions, col='blue')
qplot(training$waiting, training$eruptions, col='blue')
plot(training$waiting, training$eruptions, col='blue')
plot(training$waiting, training$eruptions, col='blue', xlab='Waiting', ylab='Eruptions')
qplot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
lm1 <- train(eruptions ~ ., data=training)
lm1 <- lm(eruptions ~ ., data=training)
lm1
summary(lm1)
qplot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
plot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
lines(training$waiting, lm1$fitted, lwd=3)
?lines
qplot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
qplot(training$waiting, lm1$fitted, geom="line")
qplot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions') + qplot(training$waiting, lm1$fitted, geom="line")
qplot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions') + qplot(training$waiting, lm1$fitted, geom="line")
p1 <- qplot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
p2 <- qplot(training$waiting, lm1$fitted, geom="line")
p1 <- qplot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
p1
p2
p1 + p2
p2 <- geom_line(training$waiting, lm1$fitted)
plot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
plot(training$waiting, training$eruptions, xlab='Waiting', ylab='Eruptions')
lines(training$waiting, lm1$fitted, lwd=3)
coef(lm1)
newdata <- data.frame(waiting=80)
predict(lm1, newdata=newdata)
par(mfrow=c(1,2))
plot(training$waiting, training$eruptions, pch=19, col="blue", xlab="Waiting", ylab="Duration")
lines(training$waiting, predict(lm1), lwd=3)
plot(testing$waiting, testing$eruptions, pch=19, col="blue", xlab="Waiting", ylab="Duration")
lines(testing$waiting, predict(lm1, newdata=testing), lwd=3)
confusionMatrix(testing$type, predict(lm1,testing))
confusionMatrix(testing$waiting, predict(lm1,testing))
confusionMatrix(testing$eruptions, predict(lm1))
confusionMatrix(training$eruptions, predict(lm1))
lm1
lm1$fitted - training$eruptions
(lm1$fitted - training$eruptions)^2
sqrt(sum((lm1$fitted - training$eruptions)^2))
sqrt(sum((predict(lm1, newdata=testing) - testing$eruptions)^2))
pred1 <- predict(lm1, newdata=testing, interval="prediction")
ord <- order(testFaith$waiting)
ord <- order(testing$waiting)
or
ord
plot(testing$waiting, testing$eruptions, pch=19, col="blue")
par(mfrow=1)
par(mfrow=c(1)
)
par(mfrow=c(1,1))
plot(testing$waiting, testing$eruptions, pch=19, col="blue")
plot(testing$waiting, testing$eruptions, pch=19, col="blue")
?matlines
matlines(testing$waiting[ord], pred1[ord], type="l",,col=(1,2,2), lty=c(1,1,1), lwd=3)
matlines(testing$waiting[ord], pred1[ord], type="l",col=(1,2,2), lty=c(1,1,1), lwd=3)
matlines(testing$waiting[ord], pred1[ord], type="l",,col=c(1,2,2), lty=c(1,1,1), lwd=3)
matlines(testing$waiting[ord], pred1[ord], type="l",,col=c(1,2,2), lty=c(1,1,1), lwd=3)
matlines(testing$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty=c(1,1,1), lwd=3)
matlines(testing$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty=c(1,1,1), lwd=3)
modelFit <- train(eruptions ~ waiting, method='lm', data=training)
summary(modelFit)
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
Wage <- subset(Wage, select=-c(logwage))
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
Wage <- subset(Wage, select=-c(logwage))
summary(Wage)
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
Wage <- subset(Wage, select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(Wage, p=0.7, list=F)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[, c('age', 'education', 'jobclass')], y=training$wage, plots='pairs')
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
Wage <- subset(Wage$wage, select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(Wage, p=0.7, list=F)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[, c('age', 'education', 'jobclass')], y=training$wage, plots='pairs')
training
featurePlot(x=training[, c('age', 'education', 'jobclass')], y=training$wage, plots='pairs')
training$wage
training[, c('age', 'education', 'jobclass')]
dim(training[, c('age', 'education', 'jobclass')])
length(training)
dim(training)
featurePlot(x=training[, c('age', 'education', 'jobclass')], y=training$wage, plots='pairs')
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(Wage$wage, p=0.7, list=F)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[, c('age', 'education', 'jobclass')], y=training$wage, plots='pairs')
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(wage, age, data=training)
qplot(age, wage, color=jobclass, data=training)
qplot(age, wage, color=education, data=training)
modelFit <- train(wage ~ age + jobclass + education, method='lm', data=training)
finMod <- modelFit$finalModel
print(modFit)
modFit <- train(wage ~ age + jobclass + education, method='lm', data=training)
finMod <- modFit$finalModel
finMod
modFit
print(modFit)
finMod
plot(finMod)
plot(finMod, 1, pch=19, cex=0.5, col='#00000010')
qplot(finMod$fitted, finMod$residuals)
qplot(finMod$fitted, finMod$residuals, color=race, data=training)
qplot(finMod$fitted, finMod$residuals, color=race)
qplot(finMod$fitted, finMod$residuals, color=race, data=training)
plot(finModel$residuals, pch=19)
plot(finMod$residuals, pch=19)
plot(finMod$residuals, pch=19)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
AlzheimerDisease
diagnosis
predictors
names(predictors)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
mixtures
dim(mixtures)
names(mixtures)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
inTrain
length(inTrain)
dim(mixtures)
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(training$Superplasticizer, geom = 'hist')
qplot(training$Superplasticizer, geom = 'histogram')
qplot(log10(training$Superplasticizer), geom = 'histogram')
qplot(training$Superplasticizer, geom = 'histogram')
qplot(log10(training$Superplasticizer), geom = 'histogram')
qplot(log10(testing$Superplasticizer), geom = 'histogram')
qplot((testing$Superplasticizer), geom = 'histogram')
qplot(testing$Superplasticizer, geom = 'histogram')
qplot(training$Superplasticizer, geom = 'histogram')
qplot(testing$Superplasticizer, geom = 'histogram')
qplot(training$Superplasticizer, geom = 'histogram')
qplot(training$Superplasticizer, geom = 'histogram')
training$Superplasticizer
log10(training$Superplasticizer)
training$Superplasticizer
training$Superplasticizer < 0.004
training$Superplasticizer < 0
SUM(training$Superplasticizer < 0)
sum(training$Superplasticizer < 0)
training$Superplasticizer < 0
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
names(training)
startsWith
library(gdata)
install.packages('gdata')
library(gdata)
startsWith('hello', 'he')
names(training)
startsWith(names(training),'IL')
IL <- names(trainint)[startsWith(names(training),'IL')]
IL <- names(training)[startsWith(names(training),'IL')]
IL
IL
IL
training[, IL]
dim(training[, IL])
ex <- training[, IL]
ex
preProc <- preProcess(ex,method="pca", pcaComp=2)
preProc
ex
z <- preProcess(ex, method='pca', thresh=0.9)
z
preProcess(ex,method="pca", pcaComp=2)
z <- preProcess(ex, method='pca', thresh=0.9)
z
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL
ex <- training[, IL]
ex
dim(ex)
training$diagnosis
ex <- training[, c(IL, 'diagnosis')]
ex
names(ex)
mod1 <- train(training, method='glm')
mod1 <- train(diagnosis ~ ., data=training, method='glm')
warnings()
mod1
mod1
confusionMatrix(testing$diagnosis, predict(mod1, newdata=testing))
mod1 <- train(diagnosis ~ ., data=training, method='glm')
confusionMatrix(testing$diagnosis, predict(mod1, newdata=testing))
training
names(training)
IL <- names(training)[startsWith(names(training),'IL')]
IL
ex <- training[, c(IL, 'diagnosis')]
mod1 <- train(diagnosis ~ ., data=ex, method='glm')
mod1
confusionMatrix(testing$diagnosis, predict(mod1, newdata=testing))
mod2 <- train(diagnosis ~ ., data=ex, method='glm', preProcess='pca', trControl = trainControl(preProcOptions = list(thresh = 0.8)))
mod2
confusionMatrix(testing$diagnosis, predict(mod2, newdata=testing))
ls
ls
ls()
?rpois
set.seed(1)
rpois(5, 2)
?rnorm
rnorm(10)
qpos
rep(0:1, each=5)
swirl
library.load('swirl')
aa <- c('a','b')
saveRDS(aa, 'bla.rds')
saveRDS(aa, 'bla.rds')
saveRDS(aa, 'bla.rds')
readRDS('bla.rds')
library('caret')   # learning
library('rattle')  # plotting of trees
# parallel computing to utilize multiple cores
library(doParallel)
registerDoParallel(cores=4)
bench <- read.csv('pml-testing.csv')
fdata <- read.csv('pml-training.csv')
# load/save models
#saveRDS(mod, file="mod.v1.rds")
#mod = readRDS("mod.v1.rds")
# split full dataset (fdata) into train/val/test using 60-20-20 fractions
set.seed(1)
p6 <- createDataPartition(fdata$classe, p=0.6, list=F)
train <- fdata[p6, ]  # 60%
tv <- fdata[-p6, ]    # 40%
p5 <- createDataPartition(tv$classe, p=0.5, list=F)
val <- tv[p5, ]       # 0.5*40% = 20%
test <- tv[-p5, ]     # 0.5*40% = 20%
setwd("~/mooc/PracticalMachineLearning/data")
library('caret')   # learning
library('rattle')  # plotting of trees
# parallel computing to utilize multiple cores
library(doParallel)
registerDoParallel(cores=4)
bench <- read.csv('pml-testing.csv')
fdata <- read.csv('pml-training.csv')
# load/save models
#saveRDS(mod, file="mod.v1.rds")
#mod = readRDS("mod.v1.rds")
# split full dataset (fdata) into train/val/test using 60-20-20 fractions
set.seed(1)
p6 <- createDataPartition(fdata$classe, p=0.6, list=F)
train <- fdata[p6, ]  # 60%
tv <- fdata[-p6, ]    # 40%
p5 <- createDataPartition(tv$classe, p=0.5, list=F)
val <- tv[p5, ]       # 0.5*40% = 20%
test <- tv[-p5, ]     # 0.5*40% = 20%
# random forest
set.seed(1)
mod <- train(classe~., data=train, method='rf')
saveRDS(mod, 'model.v01.rf.all.rds')
# decision tree
set.seed(1)
mod <- train(classe~., data=train, method='rpart')
saveRDS(mod, 'model.v02.rpart.all.rds')
# fancyRpartPlot(mod$finalModel)
# qplot(predict(modFit,testing),wage,data=testing)
# boosted decision tree
set.seed(1)
mod <- train(classe~., data=train, method='gbm')
saveRDS(mod, 'model.v03.gbm.all.rds')
warnings()
# linear discriminant
set.seed(1)
mod <- train(classe~.,data=train,method="lda")
saveRDS(mod, 'model.v04.lda.all.rds')
